<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sijie (Ada) Cheng</title>

    <meta name="author" content="Sijie Cheng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/icon.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>

    <div class="lang-switch">
      <a class="active" href="index.html">中文版</a>
      <span class="sep">|</span>
      <a href="html_en.html">English</a>
    </div>
    
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2%;width:80%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sijie (Ada) Cheng
                </p>
                <p>我目前是中国北京<a href="https://www.cs.tsinghua.edu.cn/">清华大学计算机科学与技术系</a>的二年级博士生，由<a href="http://nlp.csai.tsinghua.edu.cn/~ly/index.html">刘洋</a>教授指导，隶属于<a href="https://nlp.csai.tsinghua.edu.cn/">THUNLP</a>与<a href="https://air.tsinghua.edu.cn/">清华大学智能产业研究院（AIR）</a>。此前，我于 2023 年获得<a href="https://www.fudan.edu.cn/">复旦大学</a>硕士学位，由<a href="https://scholar.google.com/citations?user=odFW4FoAAAAJ&hl=en&oi=ao">肖仰华</a>教授在<a href="http://kw.fudan.edu.cn/">Knowledge Work Lab</a>指导。我曾获得多项荣誉与奖励，包括<i>中国科协青年人才托举工程博士生专项计划-依托中国计算机学会</i>（中国科协青年人才托举工程博士生专项计划——依托中国计算机学会），<i>上海市计算机学会优秀硕士学位论文奖</i>（上海市计算机学会优秀硕士学位论文奖），<i>国家奖学金</i>（国家奖学金），清华大学智能产业研究院（AIR）<i>院长奖学金</i>（院长奖学金），上海市<i>优秀毕业生</i>（优秀毕业生），以及<i>ICML 2024 MFM-EAI Workshop 优秀论文</i>。
                </p>
                <p>
                  <!-- <span style="color: coral"><b>😼 我已提前通过博士资格考试！！！</b></span>
                  <br> -->
                  <span style="color: #800000;"><b>👓 正在招募智能眼镜方向的 AI 全职与实习同学，并寻求以第一视角基础模型为主题的科研合作。</b></span>
                </p>
                <p style="text-align:center">
                  <a href="mailto:csj23@mails.tsinghua.edu.cn">邮箱</a> &nbsp;/&nbsp;
                  <a href="data/SijieCheng-CV.pdf">简历</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=pruwctkAAAAJ&hl=en">谷歌学术</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">推特</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/AdaCheng/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/SijieCheng.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/SijieCheng.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>研究：第一视角基础模型代表基础模型的下一代形态</b></h2>
                <p>
                  我主要关注面向具身智能（Embodied AI）的第一视角多模态大语言模型，目标是构建能够从第一人称视角像人类一样“看、想、做”的系统。
                  <ul>
                    <li><span style="color: #800000;"><b>第一视角理解：</b></span>理解人类日常活动中从第一人称视角产生的观察与交互，例如 <a href="https://arxiv.org/pdf/2311.15596"><b>EgoThink</b></a> | <a href="https://arxiv.org/pdf/2410.11623v1"><b>VidEgoThink</b></a>。 </li>
                    <li><span style="color: #800000;"><b>端侧模型训练：</b></span>训练基础模型并进一步部署到可穿戴设备或自主机器人上，例如 <a href="https://arxiv.org/pdf/2309.11235"><b>OpenChat</b></a> | <a href="https://arxiv.org/pdf/2405.15738">ConvLLaVA</a> | <a href="https://arxiv.org/pdf/2405.19783">IVM</a>。 </li>
                    <li><span style="color: #800000;"><b>预训练模型中的隐式知识：</b></span>探索与分析预训练模型所蕴含的内在知识，例如 <a href="https://arxiv.org/pdf/2110.11027"><b>FedGEMs</b></a> | <a href="https://arxiv.org/pdf/2403.07714"><b>StableToolBench</b></a> | <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26494"><b>Explanation</b></a> | <a href="https://ieeexplore.ieee.org/abstract/document/9835349"><b>Taxonomy</b></a> | <a href="https://arxiv.org/pdf/2008.03945">Commonsense</a>。</li>
                  </ul>
                </p>
              </td>
            </tr>
          </tbody></table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:0px">
                <h2><b>代表性论文</b></h2>
                <br>
                <span>完整论文列表见 <a href="https://scholar.google.com/citations?user=pruwctkAAAAJ&hl=en">这里</a>。（* 表示同等贡献。）</span>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px"></tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/videgothink.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2410.11623v1">
            <span class="papertitle">VidEgoThink：面向具身智能的第一视角视频理解能力评测</span>
              </a>
              <br>
              <strong>Sijie Cheng</strong>, 
              Kechen Fang*,
              Yangyang Yu*,
              Sicheng Zhou*,
              <a href="https://bohao-lee.github.io/">Bohao Li</a>,
              <a href="https://scholar.google.com/citations?user=rTKoFWUAAAAJ&hl=en&oi=ao">Ye Tian</a>,
              <a href="https://teaganli.github.io/">Tingguang Li</a>,
              <a href="https://www.leihan.org/">Lei Han</a>,
              <a href="https://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>
              <br>
              <em>arXiv</em>, 2024 &nbsp <font color="red"><strong>（Huggingface 每日论文 Top-1）</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
            </td>
          </tr>
        
          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/egothink.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://adacheng.github.io/EgoThink/">
            <span class="papertitle">EgoThink：评估视觉-语言模型的第一视角思维能力
              </span>
              </a>
              <br>
              <strong>Sijie Cheng*</strong>, 
              <a href="https://zhichengg.github.io/">Zhicheng Guo*</a>,
              Jingwen Wu*,
              Kechen Fang,
              <a href="https://lpeng.net/">Peng Li</a>,
              <a href="https://sites.google.com/site/thuliuhuaping/home">Huaping Liu</a>,
              <a href="https://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>
              <br>
              <em>CVPR</em>, 2024 &nbsp <font color="red"><strong>（Highlights）</strong></font>
              <br>
              <a href="https://adacheng.github.io/EgoThink/">主页</a>
              /
              <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
              /
              <a href="https://github.com/AdaCheng/EgoThink">GitHub</a>
              /
              <a href="https://huggingface.co/datasets/">数据集</a>
              /
              <a href="https://adacheng.github.io/EgoThink/#leaderboard">排行榜</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/openchat.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2309.11235">
            <span class="papertitle">OpenChat：通过混合质量数据推动开源语言模型发展
        </span>
              </a>
              <br>
              Guan Wang*,
              <strong>Sijie Cheng*</strong>, 
              <a href="https://zhanxianyuan.xyz/">Xianyuan Zhan</a>, 
              Xiangang Li,
              Song Sen, 
              <a href="https://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>

              <br>
              <em>ICLR</em>, 2024 &nbsp <font color="red"><strong>（GitHub 星标 5.2k+，Huggingface 下载 100k+）</strong></font>
              <br>
              <a href="https://arxiv.org/pdf/2309.11235">arXiv</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stabletoolbench.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2403.07714">
                <span class="papertitle">StableToolBench：迈向稳定的大规模工具学习评测基准</span>
              </a>
              <br>
              
              <a href="https://zhichengg.github.io/">Zhicheng Guo</a>,
              <strong>Sijie Cheng</strong>, 
              Hao Wang,
              <a href="https://lsh.plus/-lshwebsite/">Shihao Liang</a>,
              <a href="https://yujia-qin.github.io/">Yujia Qin</a>,
              <a href="https://lpeng.net/">Peng Li</a>,
              <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
              <a href="https://www.cs.tsinghua.edu.cn/csen/info/1312/4394.htm">Maosong Sun</a>,
              <a href="https://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>
              <br>
              <em>ACL</em>, 2024 &nbsp <font color="red"><strong>（GitHub 星标 100+）</strong></font>
              <br>
              <a href="https://zhichengg.github.io/stb.github.io/">项目主页</a>
              /
              <a href="https://arxiv.org/abs/2403.07714">arXiv</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ivm.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2405.19783">
                <span class="papertitle">指令引导的视觉掩码</span>
              </a>
              <br>
              
              Jinliang Zheng*,
              <a href="https://facebear-ljx.github.io/">Jianxiong Li*</a>,
              <strong>Sijie Cheng</strong>, 
              Yinan Zheng,
              Jiaming Li,
              <a href="https://jihaonew.github.io/">Jihao Liu</a>,
              <a href="https://liuyu.us/">Yu Liu</a>,
              <a href="https://air.tsinghua.edu.cn/en/info/1046/1194.htm#:~:text=Jingjing%20Liu%20is%20Professor%2C%20Principal,ICLR%2C%20CVPR%2C%20etc.)">Jingjing Liu</a>,              
              <a href="https://zhanxianyuan.xyz/">Xianyuan Zhan</a>, 
              <br>
              <em>NeurIPS</em>, 2024 &nbsp <font color="red"><strong>（ICML 2024 MFM-EAI Workshop 优秀论文）</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2405.19783">arXiv</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/decisionnce.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.18137">
                <span class="papertitle">DecisionNCE：通过隐式偏好学习获得具身多模态表示</span>
              </a>
              <br>
              
              <a href="https://facebear-ljx.github.io/">Jianxiong Li*</a>,
              Jinliang Zheng*,
              Yinan Zheng,
              Liyuan Mao,
              Xiao Hu,
              <strong>Sijie Cheng</strong>, 
              Haoyi Niu,
              <a href="https://jihaonew.github.io/">Jihao Liu</a>,
              <a href="https://liuyu.us/">Yu Liu</a>,
              <a href="https://air.tsinghua.edu.cn/en/info/1046/1194.htm#:~:text=Jingjing%20Liu%20is%20Professor%2C%20Principal,ICLR%2C%20CVPR%2C%20etc.)">Jingjing Liu</a>,              
              <a href="https://scholar.google.com/citations?user=mDOMfxIAAAAJ&hl=en">Yaqin Zhang</a>
              <a href="https://zhanxianyuan.xyz/">Xianyuan Zhan</a>, 
              <br>
              <em>ICML</em>, 2024 &nbsp <font color="red"><strong>（ICML 2024 MFM-EAI Workshop 优秀论文）</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2402.18137">arXiv</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/neon.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.11027">
                <span class="papertitle">通过正确实例化进行无监督解释生成</span>
              </a>
              <br>
              
              <strong>Sijie Cheng</strong>, 
              <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>,
              <a href="https://jiangjiechen.github.io/">Jiangjie Chen</a>,
              Zhixing Li,
              <a href="http://nlp.csai.tsinghua.edu.cn/~ly/index.html">Yang Liu</a>,
              <a href="https://ikekonglp.github.io/">Lingpeng Kong</a>
              <br>
              <em>AAAI</em>, 2023 <font color="red"><strong>（Oral）</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2402.18137">arXiv</a>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/taxonomy.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2203.14921">
                <span class="papertitle">从已做之事中学习所需：基于用户行为监督的产品类目体系扩展</span>
              </a>
              <br>
              
              <strong>Sijie Cheng</strong>, 
              Zhouhong Gu,
              <a href="https://mila.quebec/en/directory/bang-liu">Bang Liu</a>,
              Rui Xie,
              Wei Wu,
              <a href="https://scholar.google.com/citations?user=odFW4FoAAAAJ&hl=en&oi=ao">Yanghua Xiao</a>,
              <br>
              <em>ICDE</em>, 2022 <font color="red"><strong>（已授权国家发明专利）</strong> </font>
              <br>
              <a href="https://arxiv.org/pdf/2203.14921">arXiv</a>
            </td>
          </tr>
          
          <tr style="padding:0px">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/FedGEMS.png' width=100%>
              </div>
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.11027">
                <span class="papertitle">FedGEMS：通过选择性知识融合实现更大规模的服务器端联邦学习模型</span>
              </a>
              <br>
              
              <strong>Sijie Cheng</strong>, 
              Jingwen Wu,
              <a href="https://scholar.google.com/citations?user=odFW4FoAAAAJ&hl=en&oi=ao">Yanghua Xiao</a>,
              <a href="https://sites.google.com/site/yangliuveronica/">Yang (Veronica) Liu</a>,
              <a href="http://nlp.csai.tsinghua.edu.cn/~ly/index.html">Yang Liu</a>
              <br>
              <em>Google Workshop on Federated Learning and Analytics</em>, 2022 <font color="red"><strong>（已授权国家发明专利）</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2402.18137">arXiv</a>
            </td>
          </tr>

          </tbody></table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:0px">
                <h2><b>实习经历</b></h2>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>  
            <tr>
              <td width="100%" valign="center" style="padding:0px">
                <ul>
                  <li>
                    <span class="papertitle">Rayneo 基础模型组 - 实习生 <em>（2025 年 1 月 - 至今）</em></span>
                    <br>
                    负责人：<a>Hongwei Li（CEO）</a>
                  </li>
                  <li>
                    <span class="papertitle">腾讯 Robotics X - 研究实习生 <em>（2024 年 6 月 - 2024 年 12 月）</em></span>
                    <br>
                    负责人：<a href="https://www.leihan.org/">Lei Han</a>，同事：<a href="https://teaganli.github.io/">Tingguang Li</a>，<a href="https://scholar.google.com/citations?user=rTKoFWUAAAAJ&hl=en&oi=ao">Ye Tian</a>
                  </li>
                  <li>
                    <span class="papertitle">01.AI 公司预训练组 - 研究实习生 <em>（2023 年 8 月 - 2024 年 3 月）</em></span>
                    <br>
                    负责人：<a href="https://scholar.google.com.hk/citations?user=80YNQwMAAAAJ&hl=zh-CN">Xiangang Li</a>，同事：<a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=zh-CN">Wenhao Huang</a>，<a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=zh-CN">Xiang Yue</a>
                  </li>
                  <li>
                    <span class="papertitle">创新工场投资部 - 投资实习生 <em>（2023 年 2 月 - 2023 年 12 月）</em></span>
                    <br>
                    负责人：<a href="https://www.chuangxin.com/portfolio/items/ren-bobing">Bobing Ren</a>
                  </li>
                  <li>
                    <span class="papertitle">上海 AI Lab 自然语言处理组 - 研究实习生 <em>（2022 年 3 月 - 2022 年 12 月）</em></span>
                    <br>
                    负责人：<a href="https://ikekonglp.github.io/">Prof. Lingpeng Kong</a>，同事：<a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>
                  </li>
                  <li>
                    <span class="papertitle">清华大学智能产业研究院（AIR） - 研究实习生 <em>（2021 年 6 月 - 2023 年 8 月）</em></span>
                    <br>
                    负责人：<a href="http://nlp.csai.tsinghua.edu.cn/~ly/index.html">Prof. Yang Liu</a>，<a href="https://sites.google.com/site/yangliuveronica/">Yang (Veronica) Liu</a> 
                  </li>
                  <li>
                    <span class="papertitle">美团自然语言理解组 - 研究实习生 <em>（2020 年 11 月 - 2021 年 6 月）</em></span>
                    <br>
                    负责人：<a href="https://scholar.google.com/citations?user=_GaB4AQAAAAJ&hl=zh-CN">Rui Xie</a> 
                  </li>
                  <li>
                    <span class="papertitle">西湖大学文本智能实验室 - 研究实习生 <em>（2019 年 9 月 - 2020 年 9 月）</em></span>
                    <br>
                    负责人：<a href="https://frcchang.github.io/">Prof. Yue Zhang</a>，同事：<a href="https://nealcly.github.io/">Leyang Cui</a>
                  </li>
                </ul>
              </td>
            </tr>      
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:0px">
                <h2><b>受邀报告</b></h2>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>  
            <tr>
              <td width="100%" valign="center" style="padding:0px">
                <ul>
                  <li>
                    <b>大模型时代科研的核心竞争力</b>，International Conference on MultiLingual Intelligent Information Processing，北京，2024 年 11 月
                  </li>
                  <li>
                    <b>EgoThink：评估视觉-语言模型的第一视角思维能力</b>，ZhiDX，线上，2024 年 9 月
                  </li>
                  <li>
                    <b>大模型时代科研的核心竞争力</b>，第四届中国情感计算大会，南昌，2024 年 7 月
                  </li>
                  <li>
                    <b>EgoThink：评估视觉-语言模型的第一视角思维能力</b>，AITIME，线上，2024 年 4 月
                  </li>
                  <li>
                    <b>通过混合质量数据推动开源语言模型发展</b>，Next Capital，线上，2024 年 3 月
                  </li>
                  <li>
                    <b>小型与中型基础模型无处不在</b>，中国科学院，北京，中国，2024 年 3 月
                  </li>
                  <li>
                    <b>OpenChat：通过混合质量数据推动开源语言模型发展</b>，Max-likelihood Community，线上，2023 年 11 月
                  </li>
                  <li>
                    <b>如何适应 LLM 时代的科研节奏</b>，MLNLP Community，线上，2023 年 11 月
                  </li>
                  <li>
                    <b>基础模型时代的研究趋势</b>，复旦大学北京校友会，北京，中国，2023 年 11 月
                  </li>
                  <li>
                    <b>知识图谱的基础、构建与应用</b>，清华大学，北京，中国，2021 年 7 月
                  </li>
                  <li>
                    <b>追随内心：我的计算机科学经历</b>，微软亚洲研究院，北京，中国，2019 年 3 月
                  </li>
                </ul>
              </td>
            </tr>      
          </tbody></table>
  
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:0px">
                <h2><b>代表性奖励</b></h2>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>  
            <tr>
              <td width="100%" valign="center" style="padding:0px">
                <ul>
                  <li>
                    <b>中国科协青年人才托举工程博士生专项计划（依托中国计算机学会）</b>，中国，2025
                  </li>
                  <li>
                    <b>年度最佳论文奖</b>，THUMT，2024
                  </li>
                  <li>
                    <b>第一名</b>，腾讯篮球协会，2024
                  </li>
                  <li>
                    <b>院长奖学金</b>，清华大学智能产业研究院（AIR），2024
                  </li>
                  <li>
                    <b>学术会议参会资助</b>，Widening Natural Language Processing@EMNLP，2024
                  </li>
                  <li>
                    <b>优秀论文奖</b>，MFM-EAI Workshop@ICML，2024
                  </li>
                  <li>
                    <b>上海市计算机学会优秀硕士学位论文奖</b>，上海市计算机学会，2024
                  </li>
                  <li>
                    <b>会议资助</b>，第十二届国际学习表征会议（ICLR），2024
                  </li>
                  <li>
                    <b>优秀毕业生</b>，上海，2023
                  </li>
                  <li>
                    <b>国家奖学金</b>，中国，2021-2022
                  </li>
                  <li>
                    <b>第一名</b>，复旦大学研究生杯女子篮球赛，2020
                  </li>
                </ul>
              </td>
            </tr>      
          </tbody></table>
        
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:0px; text-align: center;">
                🐶 <span style="font-size: 10px">💖</span> 🤖
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
